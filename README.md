<div id="top"></div>

<!-- PROJECT SHIELDS -->
[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![MIT License][license-shield]][license-url]
[![LinkedIn][linkedin-shield]][linkedin-url]

<!-- PROJECT LOGO -->
<br />
<div align="center">
  <!-- <a href="https://github.com/Rahul5430/Speech-Emotion-Recognition-System">
    <img src="public/pec_acm_logo.jpg" alt="Logo" width="100" height="100" />
  </a> -->

  <h1 align="center">Speech Emotion Recognition System</h3>
  <!-- <h3 align="center">Speech Emotion Recognition System</h3> -->

  <p align="center">
    <p>Through all the available senses humans can actually sense the emotional state of their communication partner. The emotional detection is natural for humans but it is very difficult task for computers; although they can easily understand content based information, accessing the depth behind content is difficult and that’s what speech emotion recognition (SER) sets out to do. It is a system through which various audio speech files are classified into different emotions such as happy, sad, anger and neutral by computer. SER can be used in areas such as the medical field or customer call centers.</p> 
    
  <a href="https://github.com/Rahul5430/Speech-Emotion-Recognition-System"><strong>Explore the docs »</strong></a>
    <br />
    <a href="https://github.com/Rahul5430/Speech-Emotion-Recognition-System">View Demo</a>
    ·
    <a href="https://github.com/Rahul5430/Speech-Emotion-Recognition-System/issues">Report Bug</a>
    ·
    <a href="https://github.com/Rahul5430/Speech-Emotion-Recognition-System/issues">Request Feature</a>
  </p>
</div>


<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
        <a href="#about-the-project">About The Project</a>
        <ul>
          <li><a href="#built-with">Built With</a></li>
        </ul>
      </li>
      <li>
        <a href="#getting-started">Getting Started</a>
        <ul>
          <li><a href="#prerequisites">Prerequisites</a></li>
          <li><a href="#installation">Installation</a></li>
        </ul>
      </li>
      <li><a href="#usage">Usage</a></li>
      <li><a href="#roadmap">Roadmap</a></li>
      <li><a href="#contributing">Contributing</a></li>
      <li><a href="#license">License</a></li>
      <li><a href="#contact">Contact</a></li>
      <li><a href="#acknowledgments">Acknowledgments</a></li>
  </ol>
</details>



<!-- ABOUT THE PROJECT -->
## About The Project

<!-- <p align='middle'>
  <img src='public/homescreen.png' alt='Home Screen' width='500' />
</p> -->


### Built With
<a href="https://www.python.org/"><img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54" /></a> &nbsp; 



<!-- GETTING STARTED -->
## Getting Started

To get a local copy up and running follow these simple example steps.

### Prerequisites

* Python 3.10
  ```
  Installation steps for Python3.10 as per your OS
  ```

### Installation

_Below is an example of how you can install and set up your app._

<!-- 1. Get a free API Key at [https://example.com](https://example.com) -->
1. Clone the repo
   ```sh
   git clone https://github.com/Rahul5430/Speech-Emotion-Recognition-System.git
   ```
2. Install virtualenv
   ```sh
   pip install virtualenv
   ```
3. Create virtualenv
   ```sh
   virtualenv venv
   ```
4. Start the Virtual Environment
    - For OSX/Linux Users:
        ```sh
        source venv/bin/activate
        ```
    - For Windows Users
        ```sh
        venv/bin/activate.bat
        ```
5. Install required packages
    ```sh
    pip install -r requirements.txt
    ```
<!-- 4. Enter your API in `config.js`
   ```js
   const API_KEY = 'ENTER YOUR API';
   ``` -->


<!-- USAGE EXAMPLES -->
## Usage

- Start the Virtual Environment
    - For OSX/Linux Users:
        ```sh
        source venv/bin/activate
        ```
    - For Windows Users
        ```sh
        venv/bin/activate.bat
        ```
- Start the project
  ```sh
  ipython main.py
  ```

_For more examples, please refer to the [Documentation](https://example.com)_



<!-- ROADMAP -->
<!-- ## Roadmap

- [x] Add Changelog
- [x] Add back to top links
- [ ] Add Additional Templates w/ Examples
- [ ] Add "components" document to easily copy & paste sections of the readme
- [ ] Multi-language Support
    - [ ] Chinese
    - [ ] Spanish -->
<!-- CONTRIBUTORS -->
## Contributors
This project exists thanks to all the people who contribute. [<a href="#contributing">Contributing</a>].

<a href="https://github.com/Rahul5430/Speech-Emotion-Recognition-System/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Rahul5430/Speech-Emotion-Recognition-System" />
</a>

See the [open issues](https://github.com/Rahul5430/Speech-Emotion-Recognition-System/issues) for a full list of proposed features (and known issues).



<!-- CONTRIBUTING -->
## Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag "enhancement".
Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

Be sure to read the [contribution guidelines](CONTRIBUTING.md) before contributing.


<!-- LICENSE -->
## License

Distributed under the MIT License. See [LICENSE](LICENSE) for more information.

<!-- CONTACT -->
## Contact

[Rahul Sharma](https://rahulsharma.vercel.app/) - acmcss@pec.edu.in - rahul2702sharma@gmail.com

Project Link: [https://github.com/Rahul5430/Speech-Emotion-Recognition-System](https://github.com/Rahul5430/Speech-Emotion-Recognition-System)

<!-- ACKNOWLEDGMENTS -->
<!-- ## Acknowledgments

Use this space to list resources you find helpful and would like to give credit to. I've included a few of my favorites to kick things off!

* [React docs](https://reactjs.org/)
* [Sanity Docs](https://www.sanity.io/)
* [Tailwind CSS Docs](https://tailwindcss.com/)
* [Img Shields](https://shields.io)
* [othneildrew / Best-README-Template](https://github.com/othneildrew/Best-README-Template) -->

<p align="right">(<a href="#top">back to top</a>)</p>




<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io:/github/contributors/Rahul5430/Speech-Emotion-Recognition-System?style=for-the-badge
[contributors-url]: https://github.com/Rahul5430/Speech-Emotion-Recognition-System/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Rahul5430/Speech-Emotion-Recognition-System?style=for-the-badge
[forks-url]: https://github.com/Rahul5430/Speech-Emotion-Recognition-System/network/members
[stars-shield]: https://img.shields.io/github/stars/Rahul5430/Speech-Emotion-Recognition-System?style=for-the-badge
[stars-url]: https://github.com/Rahul5430/Speech-Emotion-Recognition-System/stargazers
[issues-shield]: https://img.shields.io/github/issues/Rahul5430/Speech-Emotion-Recognition-System?style=for-the-badge
[issues-url]: https://github.com/Rahul5430/Speech-Emotion-Recognition-System/issues
[license-shield]: https://img.shields.io/github/license/Rahul5430/Speech-Emotion-Recognition-System?style=for-the-badge
[license-url]: https://github.com/Rahul5430/Speech-Emotion-Recognition-System/blob/master/LICENSE
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555
[linkedin-url]: https://www.linkedin.com/in/rahul5430/
[product-screenshot-loginScreen]: assets/loginScreen.gif
[product-screenshot-stockScreenAndWatchlist]: assets/stockScreenAndWatchlist.gif
[product-screenshot-aboutAndProfileScreen]: assets/aboutAndProfileScreen.gif
[product-screenshot-searchScreen]: assets/searchScreen.gif